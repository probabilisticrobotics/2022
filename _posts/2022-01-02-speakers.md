---
layout: default
title: Speakers
---

<table class="table-condensed">
<tbody>
<tr>
<td style="text-align: center; vertical-align: middle;"><div class="circular--portrait"><img src="/img/burgard.jpg" alt="Wolfram Burgard"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--portrait"><img src="/img/ramos.png" alt="Fabio Ramos"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--square"><img src="/img/vidal_calleja.png" alt="Teresa Vidal Calleja"></div></td>
</tr>
<tr>
<td style="text-align: center; vertical-align: middle;"><a href="http://www2.informatik.uni-freiburg.de/~burgard/"><b>Wolfram Burgard</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="https://fabioramos.github.io/Home.html"><b>Fabio Ramos</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="https://profiles.uts.edu.au/Teresa.VidalCalleja"><b>Teresa Vidal-Calleja</b></a></td>
</tr>
<tr>
<td style="text-align: center; vertical-align: middle;">University of Technology Nuremberg (Germany)</td>
<td style="text-align: center; vertical-align: middle;">NVIDIA and University of Sydney (USA and Australia)</td>
<td style="text-align: center; vertical-align: middle;">University of Technology Sydney (Australia)</td>
</tr>
<tr>
<td>Talk: <b>Probabilistic and Deep Learning Approaches for Mobile Robots and Automated Driving</b></td>
<td>Talk: <b>Stein methods for parallelized Bayesian inference in perception, state estimation and control</b>
<details>
  <summary>Abstract: &crarr;</summary>
  <p>Uncertainty estimation is critical in all levels of robotics systems, from perception to control and sequential decision making. Bayesian inference provides a principled framework for reasoning about uncertainty but the computational cost of computing posteriors can make it impractical for deployment in robots. Fortunately, the recent availability of inexpensive, energy-efficient parallel computing hardware and differentiable programming languages has opened the possibility for the development of Bayesian inference algorithms that leverage parallelism and differentiability of both likelihood functions and priors to estimate complex posteriors. In this talk I will describe a powerful nonparametric inference method that uses both differentiability and parallelism to provide nonparametric posterior approximations in a timely manner. Stein Variational Gradient Descent and its generalizations can be used to formulate Bayesian extensions of common methods in robotics such as ICP for perception, particle filters for state estimation, and model predictive control for decision making. I will show that Stein inference scales better with the dimensionality of the data and can be implemented efficiently on GPUs. Finally, I will discuss extensions of Stein methods for sim2real and the automatic adaptation of simulators to reflect real observations.</p>
</details>
</td>
<td>Talk: <b>Probabilistic Crowd Flows for Socially Aware Navigation</b></td>
</tr>
</tbody>
</table>

<table class="table-condensed">
<tbody>
<tr>
<td style="text-align: center; vertical-align: middle;"><div class="circular--square"><img src="/img/suenderhauf.png" alt="Niko Sünderhauf"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--portrait"><img src="/img/frank.jpg" alt="Felix Frank"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--portrait"><img src="/img/posner4x.png" alt="Ingmar Posner"></div></td>
</tr>
<tr>
<td style="text-align: center; vertical-align: middle;"><a href="https://nikosuenderhauf.github.io/"><b>Niko Sünderhauf</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="https://argmax.ai/team/felix-frank/"><b>Felix Frank</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="https://eng.ox.ac.uk/people/ingmar-posner/"><b>Ingmar Posner</b></a></td>
</tr>
<tr>
<td style="text-align: center; vertical-align: middle;">Queensland University of Technology (Australia)</td>
<td style="text-align: center; vertical-align: middle;">Volkswagen (Germany)</td>
<td style="text-align: center; vertical-align: middle;">University of Oxford (United Kingdom)</td>
</tr>
<tr>
<td>Talk: <b>The importance of uncertainty for reliable perception and action</b></td>
<td>Talk: <b>Latent variable models empower probabilistic optimal control</b></td>
<td>Talk: <b>Robots in Latent Space - Learning Capable Robot Models with Deep Generative Models</b></td>
</tr>
</tbody>
</table>

<table class="table table-condensed">
<tbody>
<tr>
<!--<td><div class="circular--portrait"><img src="/img/agha.jpg" alt="Ali Agha"></div></td>-->
<td style="text-align: center; vertical-align: middle;"><div class="circular--landscape"><img src="/img/gal.jpg" alt="Yarin Gal"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--square"><img src="/img/balaji.png" alt="Balaji Lakshminarayanan"></div></td>
<td style="text-align: center; vertical-align: middle;"><div class="circular--portrait"><img src="/img/antonova.png" alt="Rika Antonova"></div></td>
</tr>
<tr>
<!--<td style="text-align: center; vertical-align: middle;"><a href="https://aliagha.site/"><b>Ali Agha</b></a></td>-->
<td style="text-align: center; vertical-align: middle;"><a href="https://www.cs.ox.ac.uk/people/yarin.gal/website/"><b>Yarin Gal</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="http://www.gatsby.ucl.ac.uk/~balaji/"><b>Balaji Lakshminarayanan</b></a></td>
<td style="text-align: center; vertical-align: middle;"><a href="https://contactrika.github.io/"><b>Rika Antonova</b></a></td>
</tr>
<tr>
<!--<td style="text-align: center; vertical-align: middle;">JPL NASA (USA)</td>-->
<td style="text-align: center; vertical-align: middle;">University of Oxford (United Kingdom)</td>
<td style="text-align: center; vertical-align: middle;">Google Brain (USA)</td>
<td style="text-align: center; vertical-align: middle;">Stanford University (USA)</td>
</tr>
<tr>
<!--<td style="text-align: center; vertical-align: middle;">Talk: <b>TBD</b></td>-->
<td>Talk: <b>Uncertainty in Deep Learning: Lessons Learned from Medical Imaging</b></td>
<td>Talk: <b>Plex: Towards Reliability using Pretrained Large Model Extensions</b>
<details>
<summary>Abstract: &crarr;</summary>
<p markdown=1>A recent trend in artificial intelligence is the use of pretrained models for language and vision tasks, which have achieved extraordinary performance but also puzzling failures. Probing these models' abilities in diverse ways is therefore critical to the field. I will talk about our recent work exploring the reliability of models, where we define a reliable model as one that not only achieves strong predictive performance but also performs well consistently over many decision-making tasks involving uncertainty (e.g., selective prediction, open set recognition, calibration under shift), robust generalization (e.g., accuracy and log-likelihood on in- and out-of-distribution datasets), and adaptation (e.g., active learning, few-shot uncertainty). Plex builds on our work on scalable building blocks for probabilistic deep learning such as Gaussian process last-layer and efficient variants of deep ensembles. We show that Plex improves the state-of-the-art across reliability tasks, and simplifies the traditional protocol as it improves the out-of-the-box performance and does not require designing scores or tuning the model for each task. [Paper](https://arxiv.org/abs/2207.07411), [Blog](https://ai.googleblog.com/2022/07/towards-reliability-in-deep-learning.html)</p>
</details>
</td>
<td>Talk: <b>Versatile active learning via focused Bayesian optimization</b></td>
</tr>
</tbody>
</table>
